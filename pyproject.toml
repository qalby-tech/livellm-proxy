[project]
name = "livellm-proxy"
version = "0.1.0"
description = "llm proxy based on pydantic ai, also includes multilmodal endpoints"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "elevenlabs>=2.16.0",
    "fastapi>=0.118.0",
    "logfire[fastapi]>=4.13.2",
    "pydantic>=2.12.0",
    "pydantic-ai-slim[anthropic,google,groq,mcp,openai]>=1.1.0"
]

[project.optional-dependencies]
testing = [
    "pytest>=8.4.2",
    "pytest-asyncio>=1.2.0"
]
